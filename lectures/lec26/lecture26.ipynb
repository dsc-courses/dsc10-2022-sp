{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import babypandas as bpd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "def standard_units(any_numbers):\n",
    "    \"Convert a sequence of numbers to standard units.\"\n",
    "    return (any_numbers - any_numbers.mean()) / np.std(any_numbers)\n",
    "\n",
    "def standardize(df):\n",
    "    \"\"\"Return a DataFrame in which all columns of df are converted to standard units.\"\"\"\n",
    "    df_su = bpd.DataFrame()\n",
    "    for column in df.columns:\n",
    "        df_su = df_su.assign(**{column + ' (su)': standard_units(df.get(column))})\n",
    "    return df_su\n",
    "\n",
    "# All of the following code is for visualization.\n",
    "def plot_regression_line(df, x, y, margin=0.02, alpha=1):\n",
    "    '''Computes the slope and intercept of the regression line between columns x and y in df (in original units) and plots it.'''\n",
    "    m = slope(df, x, y)\n",
    "    b = intercept(df, x, y)\n",
    "    \n",
    "    df.plot(kind='scatter', x=x, y=y, figsize=(10, 5), label='original data', alpha=alpha)\n",
    "    left = df.get(x).min()*(1 - margin)\n",
    "    right = df.get(x).max()*(1 + margin)\n",
    "    domain = np.linspace(left, right, 10)\n",
    "    plt.plot(domain, m*domain + b, color='purple', label='regression line')\n",
    "    plt.suptitle(format_equation(m, b), fontsize=18)\n",
    "    plt.legend();\n",
    "    \n",
    "# Just for visual purposes\n",
    "def format_equation(m, b):\n",
    "    if b > 0:\n",
    "        return r'$y = %.2fx + %.2f$' % (m, b)\n",
    "    elif b == 0:\n",
    "        return r'$y = %.2fx' % m\n",
    "    else:\n",
    "        return r'$y = %.2fx %.2f$' % (m, b)\n",
    "    \n",
    "# Don't worry about how this function works.\n",
    "def plot_errors(df, m, b, x_col='x', y_col='y'):\n",
    "    x = df.get(x_col)\n",
    "    y = m*x + b\n",
    "    df.plot(kind='scatter', x=x_col, y=y_col, figsize=(10, 5), label='original data')\n",
    "    plt.plot(x, y, color='purple', label='regression line')\n",
    "    for k in np.arange(df.shape[0]):\n",
    "        xk = df.get(x_col).iloc[k]\n",
    "        yk = np.asarray(y)[k]\n",
    "        if k == df.shape[0] - 1:\n",
    "            plt.plot([xk, xk], [yk, df.get(y_col).iloc[k]], '--', c='r', linewidth=2, label='errors')\n",
    "        else:\n",
    "            plt.plot([xk, xk], [yk, df.get(y_col).iloc[k]], '--', c='r', linewidth=2)\n",
    "    \n",
    "    plt.suptitle(format_equation(m, b), fontsize=18)\n",
    "    plt.xlim(50, 90)\n",
    "    plt.ylim(40, 100)\n",
    "    plt.legend();\n",
    "    \n",
    "def update_plot(w):\n",
    "    m = slope_widget.value\n",
    "    b = galton.get('childHeight').mean() - m * galton.get('midparentHeight').mean()\n",
    "    with out:\n",
    "        out.clear_output(wait=True)\n",
    "        plot_errors(galton, m, b, x_col='childHeight', y_col='midparentHeight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 26 ‚Äì Residuals and Inference\n",
    "\n",
    "## DSC 10, Spring 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Announcements\n",
    "\n",
    "- Lab 8 is due on **tomorrow at 11:59pm**.\n",
    "- The Final Project is due on **Wednesday 6/1 at 11:59pm**\n",
    "    - Start if you haven't already!\n",
    "- Monday is a holiday. No lecture and no discussion section.\n",
    "- The Final Exam is on **Saturday, 6/4 from 3-6pm**.\n",
    "    - In-person, on-paper exam.\n",
    "    - Work on the practice exams posted on the [Resources tab of the course website](https://dsc10.com/resources/). \n",
    "    - More details coming next week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How much progress have you made on the Final Project? \n",
    "\n",
    "### To answer, go to [menti.com](https://menti.com) and enter the code 1726 8750 or [click here](https://www.menti.com/gxcgcee42h)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Agenda\n",
    "\n",
    "- Residuals.\n",
    "- Inference for regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Quality of fit\n",
    "\n",
    "- The regression line describes the \"best linear fit\" for a given dataset.\n",
    "- The formulas for the slope and intercept work no matter what the shape of the data is.\n",
    "- But the line is only meaningful if the relationship between $x$ and $y$ is roughly linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Residuals\n",
    "\n",
    "- The errors of a regression line's predictions are called **residuals**.\n",
    "- There is one residual corresponding to each data point $(x, y)$ in the dataset.\n",
    "\n",
    "$$\\text{residual} = \\text{actual } y - \\text{predicted } y \\text{ by regression line}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Calculating residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def correlation(df, x, y):\n",
    "    '''Computes the correlation between column x and column y of df.'''\n",
    "    return (standard_units(df.get(x)) * standard_units(df.get(y))).mean()\n",
    "\n",
    "def slope(df, x, y):\n",
    "    '''Returns the slope of the regression line between columns x and y in df (in original units).'''\n",
    "    r = correlation(df, x, y)\n",
    "    return r * np.std(df.get(y)) / np.std(df.get(x))\n",
    "\n",
    "def intercept(df, x, y):\n",
    "    '''Returns the intercept of the regression line between columns x and y in df (in original units).'''\n",
    "    return df.get(y).mean() - slope(df, x, y) * df.get(x).mean()\n",
    "\n",
    "def fit(df, x, y):\n",
    "    m = slope(df, x, y)\n",
    "    b = intercept(df, x, y)\n",
    "    return m * df.get(x) + b\n",
    "\n",
    "def residual(df, x, y):\n",
    "    return df.get(y) - fit(df, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Predicting child height üë™ üìè\n",
    "\n",
    "- Is the association between `'midparentHeight'` and `'childHeight'` linear?\n",
    "    - If there is a linear association, is it strong?\n",
    "        - We can answer this using the correlation coefficient.\n",
    "        - Close to 0 = weak, close to -1/+1 = strong.\n",
    "    - Is \"linear\" the best description of the association between `'midparentHeight'` and `'childHeight'`?\n",
    "        - We'll use residuals to answer this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galton = bpd.read_csv('data/galton.csv')\n",
    "\n",
    "heights = bpd.DataFrame().assign(\n",
    "    MidParent=galton.get('midparentHeight'),\n",
    "    Child=galton.get('childHeight')\n",
    ")\n",
    "\n",
    "fitted = heights.assign(\n",
    "    fit=fit(heights, 'MidParent', 'Child'),\n",
    "    residuals=residual(heights, 'MidParent', 'Child')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_regression_line(fitted, 'MidParent', 'Child')\n",
    "\n",
    "idx = np.random.randint(0, fitted.shape[0], size=50)\n",
    "for i, k in enumerate(idx):\n",
    "    x = fitted.get('MidParent').iloc[k]\n",
    "    y = fitted.get('Child').iloc[k]\n",
    "    p = fitted.get('fit').iloc[k]\n",
    "    plt.plot([x,x], [y,p], '--', linewidth=3, color='red', label='residuals' if i==0 else None)\n",
    "plt.legend();\n",
    "print('Correlation:', correlation(galton, 'midparentHeight', 'childHeight'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The residual plot\n",
    "\n",
    "- The residual plot is the scatter plot with the original $x$ variable on the $x$ axis and residuals on the $y$ axis.\n",
    "- Residual plots describe how the error in the regression line's predictions varies.\n",
    "    $$\\text{residual} = \\text{actual } y - \\text{predicted } y \\text{ by regression line}$$\n",
    "    - If there is no pattern in the residual plot, it suggests that the linear fit is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted.plot(kind='scatter', x='MidParent', y='residuals', c='red', figsize=(10, 5), label='residuals')\n",
    "plt.axhline(0, color='k', label='y = 0')\n",
    "plt.title('Residual plot for regression between midparentHeight and childHeight')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reading the residual plot\n",
    "\n",
    "- If a linear fit is good, the residual plot:\n",
    "    - Should look like a patternless \"blob\".\n",
    "    - About half of the data points should be above the horizontal line at 0, and about half should be below.\n",
    "    - Should have similar vertical spread throughout.\n",
    "- What happens if these conditions aren't met?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The residual plot for a non-linear association üöó\n",
    "- Consider the hybrid cars dataset from earlier. \n",
    "- Let's look at a regression line that uses `'mpg'` to predict `'msrp'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid = bpd.read_csv('data/hybrid.csv')\n",
    "hybrid_fitted = hybrid.assign(\n",
    "    fit=fit(hybrid, 'mpg', 'msrp'),\n",
    "    residuals=residual(hybrid, 'mpg', 'msrp')\n",
    ")\n",
    "hybrid_fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot of the original data and regression line\n",
    "plot_regression_line(hybrid, 'mpg', 'msrp');\n",
    "print('Correlation:', correlation(hybrid, 'mpg', 'msrp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Residual plot\n",
    "hybrid_fitted.plot(kind='scatter', x='mpg', y='residuals', figsize=(10, 5), color='red', label='residuals')\n",
    "plt.axhline(0, color='k', label='y = 0')\n",
    "plt.title('Residual plot for regression between mpg and msrp')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that as `'mpg'` increases, the residuals go from being mostly large, to being mostly small, to being mostly large again. That's a pattern!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Issue #1: patterns in the residual plot\n",
    "\n",
    "- Patterns in the residual plot imply that the relationship between $x$ and $y$ may not be linear.\n",
    "    - While this can be spotted in the original scatter plot, it may be easier to identify in the residual plot.\n",
    "- In such cases, a curve may be a better choice than a line for prediction.\n",
    "    - You'll learn more about curve fitting in future courses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Another example: `'mpg'` and `'acceleration'` ‚õΩ\n",
    "\n",
    "- Let's fit a regression line to predict `'acceleration'` given `'mpg'`.\n",
    "- Let's then look at the resulting residual plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accel_mpg = hybrid.assign(\n",
    "    fit=fit(hybrid, 'acceleration', 'mpg'),\n",
    "    residuals=residual(hybrid, 'acceleration', 'mpg')\n",
    ")\n",
    "accel_mpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot of the original data and regression line\n",
    "plot_regression_line(accel_mpg, 'acceleration', 'mpg')\n",
    "print('Correlation:', correlation(accel_mpg, 'acceleration', 'mpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Residual plot\n",
    "accel_mpg.plot(kind='scatter', x='acceleration', y='residuals', figsize=(10, 5), color='red', label='residuals')\n",
    "plt.axhline(0, color='k', label='y = 0')\n",
    "plt.title('Residual plot for regression between acceleration and msrp')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the residuals tend to vary more for smaller accelerations than they do for larger accelerations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Issue #2: uneven vertical spread\n",
    "\n",
    "- If the vertical spread in a residual plot is uneven, it implies that the regression line's predictions aren't equally accurate for all inputs.\n",
    "    - This doesn't necessarily mean that fitting a nonlinear curve would be better. It just impacts how we interpret the regression line's predictions.\n",
    "- The formal term for \"uneven spread\" is **heteroscedasticity**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Anscombe's quartet\n",
    "\n",
    "<center><img src='data/anscombe.png' width=800></center>\n",
    "\n",
    "- All 4 datasets have the same mean of $x$, mean of $y$, SD of $x$, SD of $y$, and correlation.\n",
    "    - Therefore, they have the same regression line because the slope and intercept of the regression line are determined by these quantities.\n",
    "- But they all look very different!\n",
    "- Not all of them are linearly associated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Another Example: The Datasaurus Dozen ü¶ñ\n",
    "\n",
    "[This dataset](https://www.autodesk.com/research/publications/same-stats-different-graphs) encourages you to \"never trust summary statistics alone; always visualize your data\"!\n",
    "\n",
    "<center><img src='data/datasaurus.png' width=800></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Inference for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The regression model\n",
    "\n",
    "- Recall, a \"model\" is a set of assumptions about how data were generated.\n",
    "- The **regression model** states that the data in a scatter plot is generated by\n",
    "1. taking points on a perfectly straight \"true line\", and\n",
    "2. adding vertical \"noise\" to each point that has a mean of 0.\n",
    "- If the regression model is satisfied, then a dataset:\n",
    "    - is shaped like an oval, roughly around an \"invisible\" true line.\n",
    "    - has a residual plot with no patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Another perspective on regression\n",
    "\n",
    "- What we're really doing:\n",
    "    - Collecting a sample of data from a population.\n",
    "    - Fitting a regression line to that sample.\n",
    "    - Using that regression line to make predictions for inputs that are not in our sample.\n",
    "\n",
    "- What if we used a different sample? ü§î"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discussion Question\n",
    "\n",
    "What strategy will help us assess how our regression line would have been different if we'd used a different sample?\n",
    "\n",
    "- A. hypothesis testing\n",
    "- B. permutation testing\n",
    "- C. bootstrapping\n",
    "- D. central limit theorem\n",
    "\n",
    "### To answer, go to [menti.com](https://menti.com) and enter the code 1726 8750 or [click here](https://www.menti.com/gxcgcee42h)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Prediction intervals\n",
    "\n",
    "Approach:\n",
    "1. Bootstrap the sample.\n",
    "2. Compute the slope and intercept of the regression line for that sample.\n",
    "3. Repeat steps 1 and 2 many times to compute many slopes and many intercepts.\n",
    "4. Use the bootstrapped slopes and intercepts to create bootstrapped predictions, and take the middle 95% of them.\n",
    "\n",
    "This will give us a **prediction interval**, i.e. a range of reasonable values for a prediction for a single input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Resampling the scatter plot of parent/child heights\n",
    "\n",
    "Note that each time we run this cell, the resulting line is slighty different!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the dataset\n",
    "resampled = heights.sample(heights.shape[0], replace=True)\n",
    "\n",
    "# Plot line of best fit\n",
    "plot_regression_line(resampled, 'MidParent', 'Child', alpha=0.5)\n",
    "\n",
    "plt.ylim([55, 80])\n",
    "plt.xlim([62, 77]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bootstrapping predictions: parent/child heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_orig = slope(heights, 'MidParent', 'Child')\n",
    "b_orig = intercept(heights, 'MidParent', 'Child')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrapped slopes and intercepts\n",
    "boot_slopes = np.array([])\n",
    "boot_intercepts = np.array([])\n",
    "\n",
    "for i in np.arange(5000):\n",
    "    # Step 1: bootstrap the sample\n",
    "    resample = heights.sample(heights.shape[0], replace=True)\n",
    "    \n",
    "    # Step 2: compute the slope and intercept of the regression line for that sample\n",
    "    m = slope(resample, 'MidParent', 'Child')\n",
    "    b = intercept(resample, 'MidParent', 'Child')\n",
    "    boot_slopes = np.append(boot_slopes, m)\n",
    "    boot_intercepts = np.append(boot_intercepts, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### If a midparent height is 74, what is the predicted child's height?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_value = 74"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the original dataset, and hence the original slope and intercept, we get a single prediction for the input of 74."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_orig = m_orig * input_value + b_orig\n",
    "pred_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the bootstrapped slopes and intercepts, we get an interval of predictions for the input of 74."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_preds = boot_slopes * input_value + boot_intercepts\n",
    "boot_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.percentile(boot_preds, 2.5)\n",
    "r = np.percentile(boot_preds, 97.5)\n",
    "[l, r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpd.DataFrame().assign(\n",
    "    predictions=boot_preds\n",
    ").plot(kind='hist', density=True, bins=20, figsize=(10, 5), ec='w')\n",
    "plt.plot([l,r],[0.01,0.01], c='lime', linewidth=8, zorder=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How different could our prediction have been, for all inputs?\n",
    "\n",
    "Here, we'll plot 20 of our bootstrapped lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Don't worry about the code for this.\n",
    "plt.figure(figsize=(10, 5))\n",
    "x = np.arange(58, 78)\n",
    "ys = []\n",
    "for (m,b) in zip(boot_slopes[:20], boot_intercepts):\n",
    "    ys.append(m * x + b)\n",
    "    plt.plot(x, m * x + b, linewidth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 95% confidence interval for the regression line\n",
    "\n",
    "This plot shows a 95% confidence interval for where the \"true\" line lies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't worry about the code for this.\n",
    "all_lines = np.vstack(ys)\n",
    "upper = all_lines.max(axis=0)\n",
    "lower = all_lines.min(axis=0)\n",
    "\n",
    "# plot_regression_line(galton, 'midparentHeight', 'childHeight')\n",
    "plt.fill_between(x, upper, lower, alpha=.6, color='C0')\n",
    "plt.plot(x, m*x + b, color='purple');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    "- Residuals are the errors in the predictions made by the regression line:\n",
    "$$\\text{residual} = \\text{actual } y - \\text{predicted } y \\text{ by regression line}$$\n",
    "- Residual plots help us determine whether a line is a good fit to our data.\n",
    "    - No pattern in residual plot = good linear fit.\n",
    "    - Patterns in residual plot = poor linear fit.\n",
    "    - The correlation coefficient, $r$, doesn't tell the full story!\n",
    "- To see how our predictions might have been different if we'd had a different sample, bootstrap!\n",
    "    - Resample the data points and make a prediction using the regression line for each resample.\n",
    "    - Many resamples leads to many predictions. Take the middle 95% of them to get a **95% prediction interval**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Next time\n",
    "\n",
    "- We'll review in class on Wednesday and Friday.\n",
    "    - Monday is a holiday.\n",
    "- No new material after this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "livereveal": {
   "scroll": true,
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
